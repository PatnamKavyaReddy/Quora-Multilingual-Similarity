{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7995bc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a055430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bfffb2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_translated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "623587e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "85747469",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12120,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "423d39a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fb9c710a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12120, 1)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "onehot_encoder = OneHotEncoder(sparse=False) #sparse=False to return an array\n",
    "y_train = y_train.reshape(len(y_train), 1) #reshape y_train from (60000,) to (60000,1); each row is a label\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6d658f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = onehot_encoder.fit_transform(y_train) #Apply onehot encoder transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c0d71e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First use difference vectors\n",
    "\n",
    "X_train = pd.read_csv('Final_train_features_glove_difference.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2ea2b794",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12120, 300)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b4cfab9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from tensorflow.python.keras.layers import Dropout\n",
    "from sklearn.preprocessing import OneHotEncoder #Import OneHotEncoder from sklearn to convert targets to one-hot encoded vectors\n",
    "from tensorflow.python.keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7e487f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()#Initialize the sequential model\n",
    "\n",
    "# first hidden layer of 500 neurons\n",
    "model.add(Dense(500, activation='relu', input_shape=(300,)) )\n",
    "\n",
    "#Add another hidden layer with same number of neurons as previous hidden layer.\n",
    "model.add(Dense(500, activation='relu'))\n",
    "\n",
    "#Add output layer. Activation is softmax because it is multiclassification and only 1 right answer \n",
    "#Output should be of size 3\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3c57d07f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 1.0503 - accuracy: 0.4501\n",
      "Epoch 2/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.9720 - accuracy: 0.5238\n",
      "Epoch 3/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.8984 - accuracy: 0.5766\n",
      "Epoch 4/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.7974 - accuracy: 0.6433\n",
      "Epoch 5/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.6549 - accuracy: 0.7232\n",
      "Epoch 6/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.4846 - accuracy: 0.8044\n",
      "Epoch 7/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.3417 - accuracy: 0.8717\n",
      "Epoch 8/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.2222 - accuracy: 0.9215\n",
      "Epoch 9/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.1516 - accuracy: 0.9495\n",
      "Epoch 10/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.1116 - accuracy: 0.9668\n",
      "Epoch 11/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0977 - accuracy: 0.9719\n",
      "Epoch 12/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0863 - accuracy: 0.9767\n",
      "Epoch 13/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0700 - accuracy: 0.9785\n",
      "Epoch 14/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0473 - accuracy: 0.9871\n",
      "Epoch 15/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0879 - accuracy: 0.9752\n",
      "Epoch 16/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0672 - accuracy: 0.9782\n",
      "Epoch 17/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0690 - accuracy: 0.9806\n",
      "Epoch 18/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0550 - accuracy: 0.9851\n",
      "Epoch 19/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0380 - accuracy: 0.9895\n",
      "Epoch 20/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0344 - accuracy: 0.9908\n",
      "Epoch 21/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0568 - accuracy: 0.9832\n",
      "Epoch 22/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0666 - accuracy: 0.9790\n",
      "Epoch 23/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0517 - accuracy: 0.9832\n",
      "Epoch 24/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0360 - accuracy: 0.9894\n",
      "Epoch 25/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0299 - accuracy: 0.9925\n",
      "Epoch 26/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0317 - accuracy: 0.9906\n",
      "Epoch 27/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0594 - accuracy: 0.9825\n",
      "Epoch 28/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0566 - accuracy: 0.9822\n",
      "Epoch 29/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0276 - accuracy: 0.9917\n",
      "Epoch 30/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0341 - accuracy: 0.9911\n",
      "Epoch 31/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0294 - accuracy: 0.9922\n",
      "Epoch 32/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0335 - accuracy: 0.9886\n",
      "Epoch 33/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0585 - accuracy: 0.9817\n",
      "Epoch 34/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0389 - accuracy: 0.9868\n",
      "Epoch 35/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0241 - accuracy: 0.9917\n",
      "Epoch 36/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0367 - accuracy: 0.9896\n",
      "Epoch 37/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0313 - accuracy: 0.9901\n",
      "Epoch 38/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0490 - accuracy: 0.9874\n",
      "Epoch 39/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0168 - accuracy: 0.9947\n",
      "Epoch 40/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0175 - accuracy: 0.9943\n",
      "Epoch 41/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0177 - accuracy: 0.9955\n",
      "Epoch 42/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0556 - accuracy: 0.9829\n",
      "Epoch 43/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0443 - accuracy: 0.9845\n",
      "Epoch 44/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0188 - accuracy: 0.9948\n",
      "Epoch 45/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0183 - accuracy: 0.9950\n",
      "Epoch 46/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0345 - accuracy: 0.9903\n",
      "Epoch 47/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0230 - accuracy: 0.9923\n",
      "Epoch 48/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0340 - accuracy: 0.9908\n",
      "Epoch 49/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0259 - accuracy: 0.9932\n",
      "Epoch 50/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0259 - accuracy: 0.9920\n",
      "Epoch 51/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0270 - accuracy: 0.9919\n",
      "Epoch 52/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0262 - accuracy: 0.9926\n",
      "Epoch 53/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0239 - accuracy: 0.9920\n",
      "Epoch 54/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0233 - accuracy: 0.9922\n",
      "Epoch 55/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0237 - accuracy: 0.9936\n",
      "Epoch 56/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0309 - accuracy: 0.9917\n",
      "Epoch 57/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0354 - accuracy: 0.9884\n",
      "Epoch 58/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0140 - accuracy: 0.9951\n",
      "Epoch 59/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0100 - accuracy: 0.9960\n",
      "Epoch 60/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0168 - accuracy: 0.9953\n",
      "Epoch 61/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0411 - accuracy: 0.9877\n",
      "Epoch 62/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0372 - accuracy: 0.9884\n",
      "Epoch 63/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0231 - accuracy: 0.9917\n",
      "Epoch 64/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0107 - accuracy: 0.9968\n",
      "Epoch 65/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0112 - accuracy: 0.9972\n",
      "Epoch 66/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0040 - accuracy: 0.9983\n",
      "Epoch 67/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0032 - accuracy: 0.9982\n",
      "Epoch 68/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0030 - accuracy: 0.9984\n",
      "Epoch 69/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0032 - accuracy: 0.9981\n",
      "Epoch 70/100\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.0029 - accuracy: 0.9983\n",
      "Epoch 71/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0032 - accuracy: 0.9983\n",
      "Epoch 72/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0033 - accuracy: 0.9983\n",
      "Epoch 73/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0722 - accuracy: 0.9803\n",
      "Epoch 74/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.1108 - accuracy: 0.9634\n",
      "Epoch 75/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0194 - accuracy: 0.9937\n",
      "Epoch 76/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0053 - accuracy: 0.9983\n",
      "Epoch 77/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0035 - accuracy: 0.9981\n",
      "Epoch 78/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0032 - accuracy: 0.9981\n",
      "Epoch 79/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0035 - accuracy: 0.9983\n",
      "Epoch 80/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0051 - accuracy: 0.9983\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0043 - accuracy: 0.9983\n",
      "Epoch 82/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0042 - accuracy: 0.9981\n",
      "Epoch 83/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0037 - accuracy: 0.9982\n",
      "Epoch 84/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0032 - accuracy: 0.9979\n",
      "Epoch 85/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0030 - accuracy: 0.9983\n",
      "Epoch 86/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0566 - accuracy: 0.9846\n",
      "Epoch 87/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.1261 - accuracy: 0.9604\n",
      "Epoch 88/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0153 - accuracy: 0.9956\n",
      "Epoch 89/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0043 - accuracy: 0.9983\n",
      "Epoch 90/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0031 - accuracy: 0.9983\n",
      "Epoch 91/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0029 - accuracy: 0.9985\n",
      "Epoch 92/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0027 - accuracy: 0.9984\n",
      "Epoch 93/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0028 - accuracy: 0.9982\n",
      "Epoch 94/100\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.0029 - accuracy: 0.9981\n",
      "Epoch 95/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0031 - accuracy: 0.9983\n",
      "Epoch 96/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0035 - accuracy: 0.9982\n",
      "Epoch 97/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0071 - accuracy: 0.9979\n",
      "Epoch 98/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.1541 - accuracy: 0.9559\n",
      "Epoch 99/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0307 - accuracy: 0.9905\n",
      "Epoch 100/100\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0082 - accuracy: 0.9974\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x201f7661e10>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We use the adam optimizer since it generally performs well in practice\n",
    "#The loss is categorical crossentropy.\n",
    "#We will use accuracy to measure performance\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=100, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fd43f347",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv('Final_test_features_glove_difference.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "34b87780",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.argmax(model.predict(X_test), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c22bf8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = pd.read_csv('test.csv')\n",
    "\n",
    "submission = np.zeros((5195,2))\n",
    "df_submission = pd.DataFrame(submission, columns=['id', 'prediction'])\n",
    "\n",
    "df_submission['id'] = test_set['id']\n",
    "df_submission['prediction'] = predictions\n",
    "df_submission.to_csv(\"GloVe_Difference_neuralnet.csv\", index=False)\n",
    "\n",
    "#Kaggle score 0.43137"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "eaa7955f",
   "metadata": {},
   "outputs": [],
   "source": [
    "######### Now try concatenation vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8c773ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_translated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8a9a0a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5142a054",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5c93b3c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12120, 1)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "onehot_encoder = OneHotEncoder(sparse=False) #sparse=False to return an array\n",
    "y_train = y_train.reshape(len(y_train), 1) #reshape y_train from (60000,) to (60000,1); each row is a label\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1163c4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = onehot_encoder.fit_transform(y_train) #Apply onehot encoder transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1af11013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenation vectors\n",
    "\n",
    "X_train = pd.read_csv('Final_train_features_glove_concat.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2004e579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12120, 600)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "62709d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from tensorflow.python.keras.layers import Dropout\n",
    "from sklearn.preprocessing import OneHotEncoder #Import OneHotEncoder from sklearn to convert targets to one-hot encoded vectors\n",
    "from tensorflow.python.keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0abec3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()#Initialize the sequential model\n",
    "\n",
    "# first hidden layer of 500 neurons\n",
    "model.add(Dense(700, activation='relu', input_shape=(600,)) )\n",
    "\n",
    "#Add another hidden layer with same number of neurons as previous hidden layer.\n",
    "model.add(Dense(700, activation='relu'))\n",
    "\n",
    "#Add output layer. Activation is softmax because it is multiclassification and only 1 right answer \n",
    "#Output should be of size 3\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ce7b3bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 1.0750 - accuracy: 0.4021\n",
      "Epoch 2/50\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 1.0210 - accuracy: 0.4648\n",
      "Epoch 3/50\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.9778 - accuracy: 0.5071\n",
      "Epoch 4/50\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.9312 - accuracy: 0.5418\n",
      "Epoch 5/50\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.8650 - accuracy: 0.5870\n",
      "Epoch 6/50\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.7844 - accuracy: 0.6356\n",
      "Epoch 7/50\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.6895 - accuracy: 0.6880\n",
      "Epoch 8/50\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.6046 - accuracy: 0.7307\n",
      "Epoch 9/50\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.5162 - accuracy: 0.7789\n",
      "Epoch 10/50\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.4477 - accuracy: 0.8100\n",
      "Epoch 11/50\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.3809 - accuracy: 0.8455\n",
      "Epoch 12/50\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.3226 - accuracy: 0.8718\n",
      "Epoch 13/50\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.2789 - accuracy: 0.8940\n",
      "Epoch 14/50\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.2357 - accuracy: 0.9143\n",
      "Epoch 15/50\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.1947 - accuracy: 0.9269\n",
      "Epoch 16/50\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.1772 - accuracy: 0.9332\n",
      "Epoch 17/50\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.1518 - accuracy: 0.9457\n",
      "Epoch 18/50\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.1623 - accuracy: 0.9424\n",
      "Epoch 19/50\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.1168 - accuracy: 0.9575\n",
      "Epoch 20/50\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.1349 - accuracy: 0.9511\n",
      "Epoch 21/50\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.1189 - accuracy: 0.9594\n",
      "Epoch 22/50\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0970 - accuracy: 0.9662\n",
      "Epoch 23/50\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0969 - accuracy: 0.9668\n",
      "Epoch 24/50\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0820 - accuracy: 0.9723\n",
      "Epoch 25/50\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0999 - accuracy: 0.9659\n",
      "Epoch 26/50\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0852 - accuracy: 0.9710\n",
      "Epoch 27/50\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0758 - accuracy: 0.9749\n",
      "Epoch 28/50\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.1132 - accuracy: 0.9681\n",
      "Epoch 29/50\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0768 - accuracy: 0.9749\n",
      "Epoch 30/50\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0654 - accuracy: 0.9784\n",
      "Epoch 31/50\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.0654 - accuracy: 0.9785\n",
      "Epoch 32/50\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0563 - accuracy: 0.9812\n",
      "Epoch 33/50\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0655 - accuracy: 0.9765\n",
      "Epoch 34/50\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.0803 - accuracy: 0.9721\n",
      "Epoch 35/50\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0568 - accuracy: 0.9811\n",
      "Epoch 36/50\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0768 - accuracy: 0.9736\n",
      "Epoch 37/50\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0493 - accuracy: 0.9847\n",
      "Epoch 38/50\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0716 - accuracy: 0.9757\n",
      "Epoch 39/50\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0644 - accuracy: 0.9779\n",
      "Epoch 40/50\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.0290 - accuracy: 0.9904\n",
      "Epoch 41/50\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0703 - accuracy: 0.9746\n",
      "Epoch 42/50\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0482 - accuracy: 0.9848\n",
      "Epoch 43/50\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.0591 - accuracy: 0.9831\n",
      "Epoch 44/50\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.0636 - accuracy: 0.9785\n",
      "Epoch 45/50\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0344 - accuracy: 0.9878\n",
      "Epoch 46/50\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0628 - accuracy: 0.9798\n",
      "Epoch 47/50\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0449 - accuracy: 0.9842\n",
      "Epoch 48/50\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0521 - accuracy: 0.9837\n",
      "Epoch 49/50\n",
      "379/379 [==============================] - 1s 2ms/step - loss: 0.0384 - accuracy: 0.9861\n",
      "Epoch 50/50\n",
      "379/379 [==============================] - 1s 3ms/step - loss: 0.0608 - accuracy: 0.9825\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2019a1415c0>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We use the adam optimizer since it generally performs well in practice\n",
    "#The loss is categorical crossentropy.\n",
    "#We will use accuracy to measure performance\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=50, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "31cbcf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv('Final_test_features_glove_concat.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a1efc8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.argmax(model.predict(X_test), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c1d927d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = pd.read_csv('test.csv')\n",
    "\n",
    "submission = np.zeros((5195,2))\n",
    "df_submission = pd.DataFrame(submission, columns=['id', 'prediction'])\n",
    "\n",
    "df_submission['id'] = test_set['id']\n",
    "df_submission['prediction'] = predictions\n",
    "df_submission.to_csv(\"GloVe_Concat_neuralnet.csv\", index=False)\n",
    "\n",
    "#Kaggle score 0.39903"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6eb492",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
